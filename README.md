<p align="center">
  <a href="https://www.kaggle.com">
    <img src="https://img.shields.io/badge/Kaggle-blue?logo=kaggle" alt="Kaggle" />
  </a>
  <a href="https://www.python.org/">
    <img src="https://img.shields.io/badge/Python-3.11-yellow?logo=python&logoColor=white" alt="Python" />
  </a>
  <a href="https://jupyter.org/">
    <img src="https://img.shields.io/badge/Notebook-Jupyter-orange?logo=jupyter" alt="Notebook" />
  </a>
<a href="https://colab.research.google.com/">
  <img src="https://img.shields.io/badge/Google%20Colab-Open%20Notebook-orange?logo=googlecolab&logoColor=white" alt="Google Colab" />
</a>
</p>

# ğŸ”— Hybrid Model (CPU-Based): CatBoost + XGBoost + LightGBM

## ğŸ‘¤ Author

| ğŸ‘¤ **Name** | ğŸ”— **Github-Profile** | ğŸ”— **Kaggle-Profile** |
|------------|----------------|----------------|
| Riddy Mazumder | [![GitHub](https://img.shields.io/badge/GitHub-RiddyMazumder-black?logo=github)](https://github.com/RiddyMazumder) | [![Kaggle Profile](https://img.shields.io/badge/Kaggle-RiddyMazumder-blue?logo=kaggle)](https://www.kaggle.com/riddymazumder) |
| Atahar08 | [![GitHub](https://img.shields.io/badge/GitHub-Atahar08-black?logo=github)](https://github.com/Atahar08) | [![Kaggle Profile](https://img.shields.io/badge/Kaggle-Atahar08-blue?logo=kaggle)](https://www.kaggle.com/Atahar08) |

This project uses a CPU-optimized hybrid ensemble model that combines the strengths of CatBoost, XGBoost, and LightGBM to achieve strong performance on medium-scale tabular datasets within Kaggleâ€™s CPU constraints.

Instead of relying on a single algorithm, predictions from multiple gradient-boosting models are combined to improve generalization and stability.
# âš™ï¸ Why a CPU-Based Hybrid Model?

Kaggle notebooks often run on CPU-only environments, making GPU-heavy solutions impractical. This hybrid approach is designed to:

âœ… Work efficiently on CPU

âœ… Reduce overfitting through model diversity

âœ… Capture different data patterns

âœ… Improve leaderboard stability

ğŸ§© Model Components
1ï¸âƒ£ CatBoost (CPU)2ï¸âƒ£ XGBoost (CPU)3ï¸âƒ£ LightGBM (CPU)ğŸ”„ Ensemble Strategy

# Final Prediction Formula
 
````
 Final_Prediction/y_hat = (y_CatBoost + y_XGBoost + y_LightGBM) / 3
````
>This approach:
>
>Smooths individual model errors,
>Improves robustness on unseen data,
>Increases public and private leaderboard consistency.
# ğŸ† Why This Hybrid Works Well on Kaggle
| Advantage                   | Benefit                               |
| --------------------------- | ------------------------------------- |
| Model Diversity             | Captures varied feature relationships |
| CPU Optimization            | Runs within Kaggle CPU limits         |
| Reduced Overfitting         | Ensemble effect                       |
| Minimal Feature Engineering | Especially with CatBoost              |
# ğŸ“Š Recommended Use Cases

Medium-scale tabular datasets

Mixed numerical + categorical features

Kaggle competitions with CPU restrictions

Regression and Classification tasks
# ğŸš€ Key Takeaway

A CPU-based hybrid ensemble of CatBoost, XGBoost, and LightGBM delivers near-GPU-level performance while remaining fully compatible with Kaggleâ€™s CPU environment.
# ğŸ“– References
| Resource               | Link                                                                                                                       |
| ---------------------- | -------------------------------------------------------------------------------------------------------------------------- |
| Kaggle Competition     | [https://www.kaggle.com/competitions/playground-series-s5e12](https://www.kaggle.com/competitions/playground-series-s5e12) |
| CatBoost Documentation | [https://catboost.ai/docs/](https://catboost.ai/docs/)                                                                     |
| LightGBM Documentation | [https://lightgbm.readthedocs.io/](https://lightgbm.readthedocs.io/)                                                       |
| Seaborn Library        | [https://seaborn.pydata.org/](https://seaborn.pydata.org/)                                                                 |
## ğŸ“„ License

This project is licensed under the **MIT License**.

You are free to use, modify, and distribute this project for educational and personal purposes.

---

## ğŸ’¬ Feedback & Contributions

If you have any questions, suggestions, or improvements:

* ğŸ Open an issue
* ğŸ“¤ Submit a pull request

Contributions are always welcome! ğŸ˜Š

---

Happy analyzing and learning! ğŸš€
